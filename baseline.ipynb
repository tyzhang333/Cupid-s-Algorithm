{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835a240f",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9f925",
   "metadata": {},
   "source": [
    "## 1.Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df71ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887b7ccd-071a-464b-8f9f-112cb239cce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[4-6]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[0-4]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Other'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[0-4]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'[4-6]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_null  wave     gender   age  age_o  d_age   d_d_age  \\\n",
       "0        b'0'   1.0  b'female'  21.0   27.0    6.0  b'[4-6]'   \n",
       "1        b'0'   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "2        b'1'   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "3        b'0'   1.0  b'female'  21.0   23.0    2.0  b'[2-3]'   \n",
       "4        b'0'   1.0  b'female'  21.0   24.0    3.0  b'[2-3]'   \n",
       "...       ...   ...        ...   ...    ...    ...       ...   \n",
       "8373     b'1'  21.0    b'male'  25.0   26.0    1.0  b'[0-1]'   \n",
       "8374     b'1'  21.0    b'male'  25.0   24.0    1.0  b'[0-1]'   \n",
       "8375     b'1'  21.0    b'male'  25.0   29.0    4.0  b'[4-6]'   \n",
       "8376     b'1'  21.0    b'male'  25.0   22.0    3.0  b'[2-3]'   \n",
       "8377     b'1'  21.0    b'male'  25.0   22.0    3.0  b'[2-3]'   \n",
       "\n",
       "                                          race  \\\n",
       "0     b'Asian/Pacific Islander/Asian-American'   \n",
       "1     b'Asian/Pacific Islander/Asian-American'   \n",
       "2     b'Asian/Pacific Islander/Asian-American'   \n",
       "3     b'Asian/Pacific Islander/Asian-American'   \n",
       "4     b'Asian/Pacific Islander/Asian-American'   \n",
       "...                                        ...   \n",
       "8373            b'European/Caucasian-American'   \n",
       "8374            b'European/Caucasian-American'   \n",
       "8375            b'European/Caucasian-American'   \n",
       "8376            b'European/Caucasian-American'   \n",
       "8377            b'European/Caucasian-American'   \n",
       "\n",
       "                                        race_o samerace  ...  \\\n",
       "0               b'European/Caucasian-American'     b'0'  ...   \n",
       "1               b'European/Caucasian-American'     b'0'  ...   \n",
       "2     b'Asian/Pacific Islander/Asian-American'     b'1'  ...   \n",
       "3               b'European/Caucasian-American'     b'0'  ...   \n",
       "4                  b'Latino/Hispanic American'     b'0'  ...   \n",
       "...                                        ...      ...  ...   \n",
       "8373               b'Latino/Hispanic American'     b'0'  ...   \n",
       "8374                                  b'Other'     b'0'  ...   \n",
       "8375               b'Latino/Hispanic American'     b'0'  ...   \n",
       "8376  b'Asian/Pacific Islander/Asian-American'     b'0'  ...   \n",
       "8377  b'Asian/Pacific Islander/Asian-American'     b'0'  ...   \n",
       "\n",
       "      d_expected_num_interested_in_me  d_expected_num_matches like  \\\n",
       "0                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "1                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "2                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "3                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "4                            b'[0-3]'                b'[3-5]'  6.0   \n",
       "...                               ...                     ...  ...   \n",
       "8373                         b'[0-3]'                b'[3-5]'  2.0   \n",
       "8374                         b'[0-3]'                b'[3-5]'  4.0   \n",
       "8375                         b'[0-3]'                b'[3-5]'  6.0   \n",
       "8376                         b'[0-3]'                b'[3-5]'  5.0   \n",
       "8377                         b'[0-3]'                b'[3-5]'  4.0   \n",
       "\n",
       "     guess_prob_liked    d_like  d_guess_prob_liked  met  decision  \\\n",
       "0                 6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'   \n",
       "1                 5.0  b'[6-8]'            b'[5-6]'  1.0      b'1'   \n",
       "2                 NaN  b'[6-8]'            b'[0-4]'  1.0      b'1'   \n",
       "3                 6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'   \n",
       "4                 6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'   \n",
       "...               ...       ...                 ...  ...       ...   \n",
       "8373              5.0  b'[0-5]'            b'[5-6]'  0.0      b'0'   \n",
       "8374              4.0  b'[0-5]'            b'[0-4]'  0.0      b'0'   \n",
       "8375              5.0  b'[6-8]'            b'[5-6]'  0.0      b'0'   \n",
       "8376              5.0  b'[0-5]'            b'[5-6]'  0.0      b'0'   \n",
       "8377              5.0  b'[0-5]'            b'[5-6]'  0.0      b'0'   \n",
       "\n",
       "      decision_o  match  \n",
       "0           b'0'   b'0'  \n",
       "1           b'0'   b'0'  \n",
       "2           b'1'   b'1'  \n",
       "3           b'1'   b'1'  \n",
       "4           b'1'   b'1'  \n",
       "...          ...    ...  \n",
       "8373        b'1'   b'0'  \n",
       "8374        b'0'   b'0'  \n",
       "8375        b'0'   b'0'  \n",
       "8376        b'1'   b'0'  \n",
       "8377        b'1'   b'0'  \n",
       "\n",
       "[8378 rows x 123 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "data, meta = arff.loadarff(\"speeddating.arff\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0389db15-b874-41bd-b3ef-aa1ba827e04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has_null', 'wave', 'gender', 'age', 'age_o', 'd_age', 'd_d_age', 'race', 'race_o', 'samerace', 'importance_same_race', 'importance_same_religion', 'd_importance_same_race', 'd_importance_same_religion', 'field', 'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'd_pref_o_attractive', 'd_pref_o_sincere', 'd_pref_o_intelligence', 'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o', 'ambitous_o', 'shared_interests_o', 'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o', 'd_ambitous_o', 'd_shared_interests_o', 'attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important', 'shared_interests_important', 'd_attractive_important', 'd_sincere_important', 'd_intellicence_important', 'd_funny_important', 'd_ambtition_important', 'd_shared_interests_important', 'attractive', 'sincere', 'intelligence', 'funny', 'ambition', 'd_attractive', 'd_sincere', 'd_intelligence', 'd_funny', 'd_ambition', 'attractive_partner', 'sincere_partner', 'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner', 'd_attractive_partner', 'd_sincere_partner', 'd_intelligence_partner', 'd_funny_partner', 'd_ambition_partner', 'd_shared_interests_partner', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'd_sports', 'd_tvsports', 'd_exercise', 'd_dining', 'd_museums', 'd_art', 'd_hiking', 'd_gaming', 'd_clubbing', 'd_reading', 'd_tv', 'd_theater', 'd_movies', 'd_concerts', 'd_music', 'd_shopping', 'd_yoga', 'interests_correlate', 'd_interests_correlate', 'expected_happy_with_sd_people', 'expected_num_interested_in_me', 'expected_num_matches', 'd_expected_happy_with_sd_people', 'd_expected_num_interested_in_me', 'd_expected_num_matches', 'like', 'guess_prob_liked', 'd_like', 'd_guess_prob_liked', 'met', 'decision', 'decision_o', 'match']\n"
     ]
    }
   ],
   "source": [
    "print(meta.names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b71c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decision  decision_o\n",
      "0         1           0\n",
      "1         1           0\n",
      "2         1           1\n",
      "3         1           1\n",
      "4         1           1\n",
      "decision      int64\n",
      "decision_o    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.replace('\\r', '', regex=False)\n",
    "df.columns = df.columns.str.replace('\\n', '', regex=False)\n",
    "\n",
    "def safe_to_int(x):\n",
    "    if isinstance(x, bytes):\n",
    "        return int(x.decode(\"utf-8\"))\n",
    "    elif isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s.startswith(\"b'\") and s.endswith(\"'\"):\n",
    "            s = s[2:-1]      \n",
    "        return int(s)\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "for col in [\"decision\", \"decision_o\"]:\n",
    "    df[col] = df[col].map(safe_to_int)\n",
    "\n",
    "print(df[[\"decision\", \"decision_o\"]].head())\n",
    "print(df[[\"decision\", \"decision_o\"]].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31289c0c-f751-4143-86ab-eebc3b6ba151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns contain _o：\n",
      "['age_o', 'race_o', 'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'd_pref_o_attractive', 'd_pref_o_sincere', 'd_pref_o_intelligence', 'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o', 'ambitous_o', 'shared_interests_o', 'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o', 'd_ambitous_o', 'd_shared_interests_o', 'decision_o']\n",
      "columns contain partner：\n",
      "['attractive_partner', 'sincere_partner', 'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner', 'd_attractive_partner', 'd_sincere_partner', 'd_intelligence_partner', 'd_funny_partner', 'd_ambition_partner', 'd_shared_interests_partner']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns contain _o：\")\n",
    "print([c for c in df.columns if \"_o\" in c])\n",
    "print(\"columns contain partner：\")\n",
    "print([c for c in df.columns if \"partner\" in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fc8057-e259-48b8-9cb7-40e2968b0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate partner（decision）\n",
    "features_decision = [\n",
    "    \"attractive_partner\",\n",
    "    \"sincere_partner\",\n",
    "    \"intelligence_partner\",\n",
    "    \"funny_partner\",\n",
    "    \"ambition_partner\",\n",
    "    \"shared_interests_partner\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe04fc0-531c-4e5a-b622-2b455934097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data size 8378  After cleaning (decision) data size: 7040\n",
      "\n",
      "=== decision: Logistic Regression ===\n",
      "Accuracy: 0.7476325757575758\n",
      "F1: 0.6993795826283136\n",
      "ROC-AUC: 0.8253947725596399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      1201\n",
      "           1       0.72      0.68      0.70       911\n",
      "\n",
      "    accuracy                           0.75      2112\n",
      "   macro avg       0.74      0.74      0.74      2112\n",
      "weighted avg       0.75      0.75      0.75      2112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- decision ----------\n",
    "cols_dec = features_decision + [\"decision\"]\n",
    "df_dec = df[cols_dec].dropna()\n",
    "\n",
    "print(\"Original data size\", df.shape[0], \" After cleaning (decision) data size:\", df_dec.shape[0])\n",
    "\n",
    "X_dec = df_dec[features_decision].astype(float)\n",
    "y_dec = df_dec[\"decision\"]\n",
    "\n",
    "X_train_dec, X_test_dec, y_train_dec, y_test_dec = train_test_split(\n",
    "    X_dec, y_dec, test_size=0.3, random_state=42, stratify=y_dec\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg_pipe_dec = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "log_reg_pipe_dec.fit(X_train_dec, y_train_dec)\n",
    "y_pred_dec_lr = log_reg_pipe_dec.predict(X_test_dec)\n",
    "y_prob_dec_lr = log_reg_pipe_dec.predict_proba(X_test_dec)[:, 1]\n",
    "\n",
    "print(\"\\n=== decision: Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_dec, y_pred_dec_lr))\n",
    "print(\"F1:\", f1_score(y_test_dec, y_pred_dec_lr))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_dec, y_prob_dec_lr))\n",
    "print(classification_report(y_test_dec, y_pred_dec_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1990d9da-b527-4631-88ed-aa9fb2122571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== decision: Random Forest ===\n",
      "Accuracy: 0.7135416666666666\n",
      "F1: 0.658770445572476\n",
      "ROC-AUC: 0.7848353594836356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75      1201\n",
      "           1       0.68      0.64      0.66       911\n",
      "\n",
      "    accuracy                           0.71      2112\n",
      "   macro avg       0.71      0.70      0.71      2112\n",
      "weighted avg       0.71      0.71      0.71      2112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_dec = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_dec.fit(X_train_dec, y_train_dec)\n",
    "y_pred_dec_rf = rf_dec.predict(X_test_dec)\n",
    "y_prob_dec_rf = rf_dec.predict_proba(X_test_dec)[:, 1]\n",
    "\n",
    "print(\"\\n=== decision: Random Forest ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_dec, y_pred_dec_rf))\n",
    "print(\"F1:\", f1_score(y_test_dec, y_pred_dec_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_dec, y_prob_dec_rf))\n",
    "print(classification_report(y_test_dec, y_pred_dec_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5927d214-1812-4956-bb21-bf874da8801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_o', 'race_o', 'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'd_pref_o_attractive', 'd_pref_o_sincere', 'd_pref_o_intelligence', 'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o', 'ambitous_o', 'shared_interests_o', 'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o', 'd_ambitous_o', 'd_shared_interests_o', 'decision_o']\n",
      "\n",
      " Original data size: 8378  After cleaning (decision_o) data size: 7031\n"
     ]
    }
   ],
   "source": [
    "for col in [\"decision\", \"decision_o\"]:\n",
    "    if df[col].dtype != \"int64\" and df2[col].dtype != \"int32\":\n",
    "        df[col] = df2[col].astype(str).astype(int)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.replace('\\r', '', regex=False)\n",
    "df.columns = df.columns.str.replace('\\n', '', regex=False)\n",
    "\n",
    "print([c for c in df.columns if \"_o\"   in c])  \n",
    "\n",
    "features_decision_o = [\n",
    "    \"attractive_o\",\n",
    "    \"sinsere_o\",\n",
    "    \"intelligence_o\",\n",
    "    \"funny_o\",\n",
    "    \"ambitous_o\",           \n",
    "    \"shared_interests_o\",\n",
    "]\n",
    "\n",
    "cols_deco = features_decision_o + [\"decision_o\"]\n",
    "df_deco = df[cols_deco].dropna()\n",
    "\n",
    "print(\"\\n Original data size:\", df.shape[0], \" After cleaning (decision_o) data size:\", df_deco.shape[0])\n",
    "\n",
    "X_deco = df_deco[features_decision_o].astype(float)\n",
    "y_deco = df_deco[\"decision_o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0462bb-5814-4e34-abe9-62d701d45ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== decision_o: Logistic Regression ===\n",
      "Accuracy: 0.7568720379146919\n",
      "F1: 0.7086882453151618\n",
      "ROC-AUC: 0.8340173708606423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      1199\n",
      "           1       0.73      0.68      0.71       911\n",
      "\n",
      "    accuracy                           0.76      2110\n",
      "   macro avg       0.75      0.75      0.75      2110\n",
      "weighted avg       0.76      0.76      0.76      2110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_deco, X_test_deco, y_train_deco, y_test_deco = train_test_split(\n",
    "    X_deco, y_deco, test_size=0.3, random_state=42, stratify=y_deco\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg_pipe_deco = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "log_reg_pipe_deco.fit(X_train_deco, y_train_deco)\n",
    "y_pred_deco_lr = log_reg_pipe_deco.predict(X_test_deco)\n",
    "y_prob_deco_lr = log_reg_pipe_deco.predict_proba(X_test_deco)[:, 1]\n",
    "\n",
    "print(\"\\n=== decision_o: Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_deco, y_pred_deco_lr))\n",
    "print(\"F1:\", f1_score(y_test_deco, y_pred_deco_lr))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_deco, y_prob_deco_lr))\n",
    "print(classification_report(y_test_deco, y_pred_deco_lr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee00ec4-0a3b-4624-9ba9-0f8b7b990bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== decision_o: Random Forest ===\n",
      "Accuracy: 0.7298578199052133\n",
      "F1: 0.6840354767184036\n",
      "ROC-AUC: 0.7969209613939168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1199\n",
      "           1       0.69      0.68      0.68       911\n",
      "\n",
      "    accuracy                           0.73      2110\n",
      "   macro avg       0.72      0.72      0.72      2110\n",
      "weighted avg       0.73      0.73      0.73      2110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_deco = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_deco.fit(X_train_deco, y_train_deco)\n",
    "y_pred_deco_rf = rf_deco.predict(X_test_deco)\n",
    "y_prob_deco_rf = rf_deco.predict_proba(X_test_deco)[:, 1]\n",
    "\n",
    "print(\"\\n=== decision_o: Random Forest ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_deco, y_pred_deco_rf))\n",
    "print(\"F1:\", f1_score(y_test_deco, y_pred_deco_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_deco, y_prob_deco_rf))\n",
    "print(classification_report(y_test_deco, y_pred_deco_rf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ds)",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
